{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we:\n",
    "1. Plot the overall of effect of forbidding the correct answer.\n",
    "2. Plot the importance of each terminal node for the dontsay effect.\n",
    "3. Plot the effect of ablating multiple terminal nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import collections\n",
    "\n",
    "import circuitsvis.attention as cv_attention\n",
    "import circuitsvis.tokens as cv_tokens\n",
    "import einops\n",
    "import marisa_trie\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "import transformer_lens.utils as tl_utils\n",
    "from fancy_einsum import einsum\n",
    "from jaxtyping import Float\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from pii import ablation, prompt_data, utils, datasets, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae57c3a3ed44c1ab995e8603e606209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe81eab580544caaf44af76af7539b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin. Berlin is the largest city in Germany and is known for its rich history, cultural attractions\n"
     ]
    }
   ],
   "source": [
    "# You will need to login to huggingface first:\n",
    "#   huggingface-cli login\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tl_model = HookedTransformer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    hf_model=hf_model,\n",
    "    device=\"cuda\",\n",
    "    move_to_device=True,\n",
    "    fold_ln=False,\n",
    "    fold_value_biases=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    print(\n",
    "        tl_model.generate(\n",
    "            \"The capital of Germany is\", max_new_tokens=20, temperature=0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14002\n"
     ]
    }
   ],
   "source": [
    "df_all = datasets.get_counterfact_dataset(tl_model)\n",
    "print(len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>pararel_idx</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>target_new_str</th>\n",
       "      <th>target_true_str</th>\n",
       "      <th>fact_prefix</th>\n",
       "      <th>irrelevant_word</th>\n",
       "      <th>prompt_c</th>\n",
       "      <th>prompt_nc0</th>\n",
       "      <th>prompt_nc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3348</td>\n",
       "      <td>10929</td>\n",
       "      <td>P495</td>\n",
       "      <td>Pinoy Idol</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Pinoy Idol, that was from</td>\n",
       "      <td>fox</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6515</td>\n",
       "      <td>6929</td>\n",
       "      <td>P17</td>\n",
       "      <td>Guillaumes</td>\n",
       "      <td>Norway</td>\n",
       "      <td>France</td>\n",
       "      <td>Guillaumes, which is located in</td>\n",
       "      <td>kiwi</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3342</td>\n",
       "      <td>8551</td>\n",
       "      <td>P27</td>\n",
       "      <td>Howe Yoon Chong</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Howe Yoon Chong, who has a citizenship from</td>\n",
       "      <td>dog</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8494</td>\n",
       "      <td>9273</td>\n",
       "      <td>P463</td>\n",
       "      <td>Mexico national football team</td>\n",
       "      <td>Hamas</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>Mexico national football team is a member of</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20754</td>\n",
       "      <td>10478</td>\n",
       "      <td>P495</td>\n",
       "      <td>The Last Hunter</td>\n",
       "      <td>Japan</td>\n",
       "      <td>Italy</td>\n",
       "      <td>The Last Hunter originated in</td>\n",
       "      <td>cloud</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an obedient assistant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  pararel_idx relation_id                        subject  \\\n",
       "0     3348        10929        P495                     Pinoy Idol   \n",
       "1     6515         6929         P17                     Guillaumes   \n",
       "2     3342         8551         P27                Howe Yoon Chong   \n",
       "3     8494         9273        P463  Mexico national football team   \n",
       "4    20754        10478        P495                The Last Hunter   \n",
       "\n",
       "  target_new_str target_true_str  \\\n",
       "0         Norway     Philippines   \n",
       "1         Norway          France   \n",
       "2        Belgium       Singapore   \n",
       "3          Hamas            FIFA   \n",
       "4          Japan           Italy   \n",
       "\n",
       "                                    fact_prefix irrelevant_word  \\\n",
       "0                     Pinoy Idol, that was from             fox   \n",
       "1               Guillaumes, which is located in            kiwi   \n",
       "2   Howe Yoon Chong, who has a citizenship from             dog   \n",
       "3  Mexico national football team is a member of      toothbrush   \n",
       "4                 The Last Hunter originated in           cloud   \n",
       "\n",
       "                                            prompt_c  \\\n",
       "0  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "1  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "2  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "3  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "4  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "\n",
       "                                          prompt_nc0  \\\n",
       "0  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "1  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "2  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "3  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "4  [INST] <<SYS>>\\nYou are an obedient assistant ...   \n",
       "\n",
       "                                          prompt_nc1  \n",
       "0  [INST] <<SYS>>\\nYou are an obedient assistant ...  \n",
       "1  [INST] <<SYS>>\\nYou are an obedient assistant ...  \n",
       "2  [INST] <<SYS>>\\nYou are an obedient assistant ...  \n",
       "3  [INST] <<SYS>>\\nYou are an obedient assistant ...  \n",
       "4  [INST] <<SYS>>\\nYou are an obedient assistant ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = df_all.sample(\n",
    "    frac=0.1,\n",
    "    random_state=42,\n",
    ").reset_index(drop=True)\n",
    "print(len(df_raw))\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are an obedient assistant who only responds with a single word (with no punctuation). You try to complete sentences truthfully. However, you are not allowed to say the forbidden word Antarctica.\n",
      "<</SYS>>\n",
      "history of Africa is located in the continent [/INST] \n",
      "Rank 0. Logit: 16.81 Prob: 30.47% Tokens: ( 2866) |Cont|inent|</s>|\n",
      "Rank 1. Logit: 16.64 Prob: 25.66% Tokens: (25523) |continent|</s>|\n",
      "Rank 2. Logit: 16.44 Prob: 20.95% Tokens: (10557) |Africa|</s>|\n",
      "Rank 3. Logit: 16.08 Prob: 14.62% Tokens: (18585) |Sure|!|Here|is|my|response|:|\n",
      "|Cont|inent|</s>|\n",
      "Rank 4. Logit: 14.81 Prob:  4.12% Tokens: ( 3869) |Yes|</s>|\n",
      "\n",
      "[INST] <<SYS>>\n",
      "You are an obedient assistant who only responds with a single word (with no punctuation). You try to complete sentences truthfully. However, you are not allowed to say the forbidden word helicopter.\n",
      "<</SYS>>\n",
      "history of Africa is located in the continent [/INST] \n",
      "Rank 0. Logit: 17.50 Prob: 37.33% Tokens: ( 2866) |Cont|inent|</s>|\n",
      "Rank 1. Logit: 17.38 Prob: 32.96% Tokens: (25523) |continent|</s>|\n",
      "Rank 2. Logit: 16.48 Prob: 13.53% Tokens: (18585) |Sure|!|Here|is|my|response|:|\n",
      "|A|frica|</s>|\n",
      "Rank 3. Logit: 16.41 Prob: 12.50% Tokens: (10557) |Africa|</s>|\n",
      "Rank 4. Logit: 13.93 Prob:  1.05% Tokens: ( 3869) |Yes|</s>|\n",
      "\n",
      "[INST] <<SYS>>\n",
      "You are an obedient assistant who only responds with a single word (with no punctuation). You try to complete sentences truthfully. However, you are not allowed to say the forbidden word Africa.\n",
      "<</SYS>>\n",
      "history of Africa is located in the continent [/INST] \n",
      "Rank 0. Logit: 17.62 Prob: 61.04% Tokens: ( 2866) |Cont|inent|</s>|\n",
      "Rank 1. Logit: 16.84 Prob: 27.95% Tokens: (18585) |Sure|,|I|apolog|ize|for|any|confusion|earlier|.|Here|'|s|my|re|vised|response|:|\n",
      "|Cont|inent|\n",
      "Rank 2. Logit: 14.68 Prob:  3.21% Tokens: (25523) |continent|</s>|\n",
      "Rank 3. Logit: 14.12 Prob:  1.84% Tokens: ( 8221) |Sorry|,|I|cannot|complete|that|sentence|as|it|is|not|within|my|programming|rules|to|mention|the|forb|idden|word|\n",
      "Rank 4. Logit: 13.76 Prob:  1.28% Tokens: ( 3869) |Yes|</s>|\n"
     ]
    }
   ],
   "source": [
    "idx = 8\n",
    "tl_model.remove_all_hook_fns(including_permanent=True)\n",
    "for i, prompt in enumerate(\n",
    "    [df_raw.prompt_nc0[idx], df_raw.prompt_nc1[idx], df_raw.prompt_c[idx]]\n",
    "):\n",
    "    print(prompt)\n",
    "    utils.get_top_responses(\n",
    "        prompt=prompt, model=tl_model, top_k=5, n_continuation_tokens=20\n",
    "    )\n",
    "    print() if i < 2 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VEM = vocab.VocabEquivalenceMap(tl_model)\n",
    "\n",
    "\n",
    "def p_correct(probs: torch.Tensor, correct_answer: str) -> Float:\n",
    "    tot = 0\n",
    "    for tok in VEM.get_equivalent_tokens(correct_answer):\n",
    "        tot += probs[tok]\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853321f3f9c9459682364155e8032e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "batch_size = 5\n",
    "pbar = tqdm(range(0, len(df_raw), batch_size))\n",
    "for idx_start in pbar:\n",
    "    idx_end = min(idx_start + batch_size, len(df_raw))\n",
    "\n",
    "    prompts = []\n",
    "    for idx in range(idx_start, idx_end):\n",
    "        prompts.extend(\n",
    "            [\n",
    "                df_raw.prompt_c[idx],\n",
    "                df_raw.prompt_nc0[idx],\n",
    "                df_raw.prompt_nc1[idx],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = tl_model.forward(prompts)\n",
    "\n",
    "    for i in range(idx_end - idx_start):\n",
    "        n_tokens_c = len(tl_model.to_tokens(prompts[3 * i])[0])\n",
    "        n_tokens_nc0 = len(tl_model.to_tokens(prompts[3 * i + 1])[0])\n",
    "        n_tokens_nc1 = len(tl_model.to_tokens(prompts[3 * i + 2])[0])\n",
    "\n",
    "        logits_c = logits[3 * i, n_tokens_c - 1]\n",
    "        logits_nc0 = logits[3 * i + 1, n_tokens_nc0 - 1]\n",
    "        logits_nc1 = logits[3 * i + 2, n_tokens_nc1 - 1]\n",
    "\n",
    "        answer_str = df_raw.target_true_str[idx_start + i]\n",
    "        with torch.no_grad():\n",
    "            p_correct_c = p_correct(logits_c.softmax(dim=-1), answer_str)\n",
    "            p_correct_nc0 = p_correct(logits_nc0.softmax(dim=-1), answer_str)\n",
    "            p_correct_nc1 = p_correct(logits_nc1.softmax(dim=-1), answer_str)\n",
    "\n",
    "            bf0 = p_correct_c.logit() - p_correct_nc0.logit()\n",
    "            bf1 = p_correct_c.logit() - p_correct_nc1.logit()\n",
    "\n",
    "        metrics.append(\n",
    "            dict(\n",
    "                p_correct_c=p_correct_c.item(),\n",
    "                p_correct_nc0=p_correct_nc0.item(),\n",
    "                p_correct_nc1=p_correct_nc1.item(),\n",
    "                bf0=bf0.item(),\n",
    "                bf1=bf1.item(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "df_raw = df_raw.assign(**pd.DataFrame(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained 414 / 1400 facts\n"
     ]
    }
   ],
   "source": [
    "filt = np.minimum(df_raw.p_correct_nc0, df_raw.p_correct_nc1) > 0.5\n",
    "df = df_raw[filt].reset_index(drop=True)\n",
    "print(f\"Retained {len(df)} / {len(df_raw)} facts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot overall effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
